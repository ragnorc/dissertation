
@article{fontaine_pharmacological_2015,
	title = {Pharmacological manipulation of transcription factor protein-protein interactions: opportunities and obstacles},
	volume = {4},
	issn = {2045-9769},
	shorttitle = {Pharmacological manipulation of transcription factor protein-protein interactions},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4365538/},
	doi = {10.1186/s13619-015-0015-x},
	abstract = {Much research on transcription factor biology and their genetic pathways has been undertaken over the last 30 years, especially in the field of developmental biology and cancer. Yet, very little is known about the molecular modalities of highly dynamic interactions between transcription factors, genomic DNA, and protein partners. Methodological breakthroughs such as RNA-seq (RNA-sequencing), ChIP-seq (chromatin immunoprecipitation sequencing), RIME (rapid immunoprecipitation mass spectrometry of endogenous proteins), and single-molecule imaging will dramatically accelerate the discovery rate of their molecular mode of action in the next few years., From a pharmacological viewpoint, conventional methods used to target transcription factor activity with molecules mimicking endogenous ligands fail to achieve high specificity and are limited by a lack of identification of new molecular targets. Protein-protein interactions are likely to represent one of the next major classes of therapeutic targets. Transcription factors, known to act mostly via protein-protein interaction, may well be at the forefront of this type of drug development. One hurdle in this field remains the difficulty to collate structural data into meaningful information for rational drug design. Another hurdle is the lack of chemical libraries meeting the structural requirements of protein-protein interaction disruption., As more attempts at modulating transcription factor activity are undertaken, valuable knowledge will be accumulated on the modality of action required to modulate transcription and how these findings can be applied to developing transcription factor drugs. Key discoveries will spawn into new therapeutic approaches not only as anticancer targets but also for other indications, such as those with an inflammatory component including neurodegenerative disorders, diabetes, and chronic liver and kidney diseases.},
	urldate = {2021-03-12},
	journal = {Cell Regeneration},
	author = {Fontaine, Frank and Overman, Jeroen and François, Mathias},
	month = mar,
	year = {2015},
	pmid = {25848531},
	pmcid = {PMC4365538},
}

@article{bai_cell_2017,
	title = {Cell cycle regulation and anticancer drug discovery},
	volume = {14},
	issn = {2095-3941},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5785171/},
	doi = {10.20892/j.issn.2095-3941.2017.0033},
	abstract = {Cellular growth, development, and differentiation are tightly controlled by a conserved biological mechanism: the cell cycle. This cycle is primarily regulated by cyclin-dependent kinase (CDK)-cyclin complexes, checkpoint kinases, and CDK inhibitors. Deregulation of the cell cycle is a hallmark of the transformation of normal cells into tumor cells. Given its importance in tumorigenesis, several cell cycle inhibitors have emerged as potential therapeutic drugs for the treatment of cancers-both as single-agent therapy and in combination with traditional cytotoxic or molecular targeting agents. In this review, we discuss the mechanisms underlying cell cycle regulation and present small-molecule anticancer drugs that are under development, including both pan-CDK inhibitors and CDK4/6-selective inhibitors. In addition, we provide an outline of some promising CDK inhibitors currently in preclinical and clinical trials that target cell cycle abnormalities in various cancers.},
	number = {4},
	urldate = {2021-03-12},
	journal = {Cancer Biology \& Medicine},
	author = {Bai, Jingwen and Li, Yaochen and Zhang, Guojun},
	month = nov,
	year = {2017},
	pmid = {29372101},
	pmcid = {PMC5785171},
	pages = {348--362},
}

@article{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
	urldate = {2021-03-06},
	journal = {arXiv:1609.04747 [cs]},
	author = {Ruder, Sebastian},
	month = jun,
	year = {2017},
	note = {arXiv: 1609.04747},
}

@misc{meninger_webcast_nodate,
	title = {Webcast {Events} - {Why} is it {Important} to {Know} the {Mode} of {Action} of {Drugs}?},
	url = {http://video.tau.ac.il/events/index.php?option=com_k2&view=item&id=5005:why-is-it-important-to-know-the-mode-of-action-of-drugs&Itemid=557},
	language = {en-gb},
	urldate = {2021-03-06},
	author = {Meninger, Naor},
}

@article{noauthor_mechanism_2010,
	title = {Mechanism matters},
	volume = {16},
	copyright = {2010 Nature Publishing Group},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/nm0410-347},
	doi = {10.1038/nm0410-347},
	abstract = {The path of drug development is fraught with hurdles. Gaining a clear understanding of how a drug works before it enters clinical trials is the intelligent route to drug discovery and could increase the likelihood for drug success.},
	language = {en},
	number = {4},
	urldate = {2021-03-06},
	journal = {Nature Medicine},
	month = apr,
	year = {2010},
	note = {Number: 4
Publisher: Nature Publishing Group},
	pages = {347--347},
}

@article{bozic_evolutionary_2013,
	title = {Evolutionary dynamics of cancer in response to targeted combination therapy},
	volume = {2},
	issn = {2050-084X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3691570/},
	doi = {10.7554/eLife.00747},
	abstract = {In solid tumors, targeted treatments can lead to dramatic regressions, but responses are often short-lived because resistant cancer cells arise. The major strategy proposed for overcoming resistance is combination therapy. We present a mathematical model describing the evolutionary dynamics of lesions in response to treatment. We first studied 20 melanoma patients receiving vemurafenib. We then applied our model to an independent set of pancreatic, colorectal, and melanoma cancer patients with metastatic disease. We find that dual therapy results in long-term disease control for most patients, if there are no single mutations that cause cross-resistance to both drugs; in patients with large disease burden, triple therapy is needed. We also find that simultaneous therapy with two drugs is much more effective than sequential therapy. Our results provide realistic expectations for the efficacy of new drug combinations and inform the design of trials for new cancer therapeutics., DOI:
http://dx.doi.org/10.7554/eLife.00747.001, As medicine becomes increasingly personalized, more and more emphasis is being placed on the development of therapies that target specific cancer-causing mutations. But while many of these drugs are effective in the short term, and do extend patient lives, tumors tend to evolve resistance to them within a few months., The key problem is that large tumors are genetically diverse. This means that for any given treatment, there is likely to be a small population of cells within the tumor that is resistant to the effects of the drug. When the drug is given to a patient, these cells will survive and multiply and this will lead ultimately to treatment failure. Given that a single drug is therefore highly unlikely to eradicate a tumor, combinations of two or more drugs may offer a higher chance of cure. This approach has been effective in the treatment of HIV as well as certain forms of leukemia., Here, Bozic et al. present a mathematical model designed to predict the effects of combination targeted therapies on tumors, based on the data obtained from 20 melanoma (skin cancer) patients. Their model revealed that if even 1 of the 6.6 billion base pairs of DNA present in a human diploid cell has undergone a mutation that confers resistance to each of two drugs, treatment with those drugs will not lead to sustained improvement for the majority of patients. This confirms the need to develop drugs that target distinct pathways., The model also reveals that combination therapy with two drugs given simultaneously is far more effective than sequential therapy where the drugs are used one after the other. Indeed, the model of Bozic et al. indicates that sequential treatment offers no chance of a cure, even when there are no cross-resistance mutations present, whereas combination therapy offers some hope of a cure, even in the presence of cross-resistance mutations., By emphasizing the need to develop drugs that target distinct pathways, and to administer them in combination rather than sequentially, the study by Bozic et al. offers valuable advice for drug development and the design of clinical trials, as well as for clinical practice., DOI:
http://dx.doi.org/10.7554/eLife.00747.002},
	urldate = {2021-03-06},
	journal = {eLife},
	author = {Bozic, Ivana and Reiter, Johannes G and Allen, Benjamin and Antal, Tibor and Chatterjee, Krishnendu and Shah, Preya and Moon, Yo Sup and Yaqubie, Amin and Kelly, Nicole and Le, Dung T and Lipson, Evan J and Chapman, Paul B and Diaz, Luis A and Vogelstein, Bert and Nowak, Martin A},
	month = jun,
	year = {2013},
	pmid = {23805382},
	pmcid = {PMC3691570},
}

@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2021-02-22},
	journal = {arXiv:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv: 1502.03167},
}

@article{moriconi_high-dimensional_2020,
	title = {High-dimensional {Bayesian} optimization using low-dimensional feature spaces},
	url = {http://arxiv.org/abs/1902.10675},
	abstract = {Bayesian optimization (BO) is a powerful approach for seeking the global optimum of expensive black-box functions and has proven successful for fine tuning hyper-parameters of machine learning models. However, BO is practically limited to optimizing 10--20 parameters. To scale BO to high dimensions, we usually make structural assumptions on the decomposition of the objective and{\textbackslash}slash or exploit the intrinsic lower dimensionality of the problem, e.g. by using linear projections. We could achieve a higher compression rate with nonlinear projections, but learning these nonlinear embeddings typically requires much data. This contradicts the BO objective of a relatively small evaluation budget. To address this challenge, we propose to learn a low-dimensional feature space jointly with (a) the response surface and (b) a reconstruction mapping. Our approach allows for optimization of BO's acquisition function in the lower-dimensional subspace, which significantly simplifies the optimization problem. We reconstruct the original parameter space from the lower-dimensional subspace for evaluating the black-box function. For meaningful exploration, we solve a constrained optimization problem.},
	urldate = {2021-02-22},
	journal = {arXiv:1902.10675 [cs, stat]},
	author = {Moriconi, Riccardo and Deisenroth, Marc P. and Kumar, K. S. Sesh},
	month = sep,
	year = {2020},
	note = {arXiv: 1902.10675},
}

@article{yang_rpd3hda1_2008,
	title = {The {Rpd3}/{Hda1} family of lysine deacetylases: from bacteria and yeast to mice and men},
	volume = {9},
	issn = {1471-0080},
	shorttitle = {The {Rpd3}/{Hda1} family of lysine deacetylases},
	doi = {10.1038/nrm2346},
	abstract = {Protein lysine deacetylases have a pivotal role in numerous biological processes and can be divided into the Rpd3/Hda1 and sirtuin families, each having members in diverse organisms including prokaryotes. In vertebrates, the Rpd3/Hda1 family contains 11 members, traditionally referred to as histone deacetylases (HDAC) 1-11, which are further grouped into classes I, II and IV. Whereas most class I HDACs are subunits of multiprotein nuclear complexes that are crucial for transcriptional repression and epigenetic landscaping, class II members regulate cytoplasmic processes or function as signal transducers that shuttle between the cytoplasm and the nucleus. Little is known about class IV HDAC11, although its evolutionary conservation implies a fundamental role in various organisms.},
	language = {eng},
	number = {3},
	journal = {Nature Reviews. Molecular Cell Biology},
	author = {Yang, Xiang-Jiao and Seto, Edward},
	month = mar,
	year = {2008},
	pmid = {18292778},
	pmcid = {PMC2667380},
	pages = {206--218},
}

@article{kikuchi_histone_2010,
	title = {Histone deacetylases are critical targets of bortezomib-induced cytotoxicity in multiple myeloma},
	volume = {116},
	issn = {1528-0020},
	doi = {10.1182/blood-2009-07-235663},
	abstract = {Bortezomib is now widely used for the treatment of multiple myeloma (MM); however, its action mechanisms are not fully understood. Despite the initial results, recent investigations have indicated that bortezomib does not inactivate nuclear factor-kappaB activity in MM cells, suggesting the presence of other critical pathways leading to cytotoxicity. In this study, we show that histone deacetylases (HDACs) are critical targets of bortezomib, which specifically down-regulated the expression of class I HDACs (HDAC1, HDAC2, and HDAC3) in MM cell lines and primary MM cells at the transcriptional level, accompanied by reciprocal histone hyperacetylation. Transcriptional repression of HDACs was mediated by caspase-8-dependent degradation of Sp1 protein, the most potent transactivator of class I HDAC genes. Short-interfering RNA-mediated knockdown of HDAC1 enhanced bortezomib-induced apoptosis and histone hyperacetylation, whereas HDAC1 overexpression inhibited them. HDAC1 overexpression conferred resistance to bortezomib in MM cells, and administration of the HDAC inhibitor romidepsin restored sensitivity to bortezomib in HDAC1-overexpressing cells both in vitro and in vivo. These results suggest that bortezomib targets HDACs via distinct mechanisms from conventional HDAC inhibitors. Our findings provide a novel molecular basis and rationale for the use of bortezomib in MM treatment.},
	language = {eng},
	number = {3},
	journal = {Blood},
	author = {Kikuchi, Jiro and Wada, Taeko and Shimizu, Rumi and Izumi, Tohru and Akutsu, Miyuki and Mitsunaga, Kanae and Noborio-Hatano, Kaoru and Nobuyoshi, Masaharu and Ozawa, Keiya and Kano, Yasuhiko and Furukawa, Yusuke},
	month = jul,
	year = {2010},
	pmid = {20351311},
	pages = {406--417},
}

@article{weiss_differential_2012,
	title = {Differential downregulation of telomerase activity by bortezomib in multiple myeloma cells-multiple regulatory pathways in vitro and ex vivo},
	volume = {107},
	copyright = {2012 The Author(s)},
	issn = {1532-1827},
	url = {https://www.nature.com/articles/bjc2012460},
	doi = {10.1038/bjc.2012.460},
	abstract = {The importance of telomerase in multiple myeloma (MM) is well established; however, its response to bortezomib has not been addressed.},
	language = {en},
	number = {11},
	urldate = {2021-02-15},
	journal = {British Journal of Cancer},
	author = {Weiss, C. and Uziel, O. and Wolach, O. and Nordenberg, J. and Beery, E. and Bulvick, S. and Kanfer, G. and Cohen, O. and Ram, R. and Bakhanashvili, M. and Magen-Nativ, H. and Shilo, N. and Lahav, M.},
	month = nov,
	year = {2012},
	note = {Number: 11
Publisher: Nature Publishing Group},
	pages = {1844--1852},
}

@article{cao_ubiquitin-proteasomal_2011,
	title = {The ubiquitin-proteasomal system is critical for multiple myeloma: implications in drug discovery},
	volume = {1},
	issn = {2160-1992},
	shorttitle = {The ubiquitin-proteasomal system is critical for multiple myeloma},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3301411/},
	abstract = {Bortezomib is a specific inhibitor of proteasomes, the most important protease complexes in protein degradation. Bortezomib can induce apoptosis of a variety of cancer cells, including leukemia, lymphoma, multiple myeloma, breast cancers, prostate cancers, lung cancers, and so on. However, extensive studies and overall evaluation suggested that multiple myeloma is the most sensitive and the best responsive disease which was later approved by Food and Drug Administration for bortezomib treatment. Because proteasomes are an essential component in the ubiquitin-proteasomal protein degradation pathway, the discovery of bortezomib implicates that the UPS is critical for myeloma pathophysiology. The UPS also contains ubiquitin, ubiquitin-activating enzymes (E1), ubiquitin-conjugating enzymes (E2), ubiquitin ligases (E3) and deubiquitinases (Dubs). In this review, we examined and analyzed the recent advancements of the UPS components in multiple myeloma and its implications in drug discovery for myeloma treatment.},
	number = {1},
	urldate = {2021-02-15},
	journal = {American Journal of Blood Research},
	author = {Cao, Biyin and Mao, Xinliang},
	month = may,
	year = {2011},
	pmid = {22432065},
	pmcid = {PMC3301411},
	pages = {46--56},
}

@article{chen_bortezomib_2011,
	title = {Bortezomib as the {First} {Proteasome} {Inhibitor} {Anticancer} {Drug}: {Current} {Status} and {Future} {Perspectives}},
	volume = {11},
	issn = {1568-0096},
	shorttitle = {Bortezomib as the {First} {Proteasome} {Inhibitor} {Anticancer} {Drug}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3306611/},
	abstract = {Targeting the ubiquitin-proteasome pathway has emerged as a rational approach in the treatment of human cancer. Based on positive preclinical and clinical studies, bortezomib was subsequently approved for the clinical use as a front-line treatment for newly diagnosed multiple myeloma patients and for the treatment of relapsed/refractory multiple myeloma and mantle cell lymphoma, for which this drug has become the staple of treatment. The approval of bortezomib by the US Food and Drug Administration (FDA) represented a significant milestone as the first proteasome inhibitor to be implemented in the treatment of malignant disease. Bortezomib has shown a positive clinical benefit either alone or as a part of combination therapy to induce chemo-/radio-sensitization or overcome drug resistance. One of the major mechanisms of bortezomib associated with its anticancer activity is through upregulation of NOXA, which is a proapoptotic protein, and NOXA may interact with the anti-apoptotic proteins of Bcl-2 subfamily Bcl-XL and Bcl-2, and result in apoptotic cell death in malignant cells. Another important mechanism of bortezomib is through suppression of the NF-κB signaling pathway resulting in the down-regulation of its anti-apoptotic target genes. Although the majority of success achieved with bortezomib has been in hematological malignancies, its effect toward solid tumors has been less than encouraging. Additionally, the widespread clinical use of bortezomib continues to be hampered by the appearance of dose-limiting toxicities, drug-resistance and interference by some natural compounds. These findings could help guide physicians in refining the clinical use of bortezomib, and encourage basic scientists to generate next generation proteasome inhibitors that broaden the spectrum of efficacy and produce a more durable clinical response in cancer patients. Other desirable applications for the use of proteasome inhibitors include the development of inhibitors against specific E3 ligases, which act at an early step in the ubiquitin-proteasome pathway, and the discovery of less toxic and novel proteasome inhibitors from natural products and traditional medicines, which may provide more viable drug candidates for cancer chemoprevention and the treatment of cancer patients in the future.},
	number = {3},
	urldate = {2021-02-15},
	journal = {Current Cancer Drug Targets},
	author = {Chen, D. and Frezza, M. and Schmitt, S. and Kanwar, J. and Dou, Q.P.},
	month = mar,
	year = {2011},
	pmid = {21247388},
	pmcid = {PMC3306611},
	pages = {239--253},
}

@article{fabregat_reactome_2017,
	title = {Reactome pathway analysis: a high-performance in-memory approach},
	volume = {18},
	issn = {1471-2105},
	shorttitle = {Reactome pathway analysis},
	url = {https://doi.org/10.1186/s12859-017-1559-2},
	doi = {10.1186/s12859-017-1559-2},
	abstract = {Reactome aims to provide bioinformatics tools for visualisation, interpretation and analysis of pathway knowledge to support basic research, genome analysis, modelling, systems biology and education. Pathway analysis methods have a broad range of applications in physiological and biomedical research; one of the main problems, from the analysis methods performance point of view, is the constantly increasing size of the data samples.},
	number = {1},
	urldate = {2021-02-09},
	journal = {BMC Bioinformatics},
	author = {Fabregat, Antonio and Sidiropoulos, Konstantinos and Viteri, Guilherme and Forner, Oscar and Marin-Garcia, Pablo and Arnau, Vicente and D’Eustachio, Peter and Stein, Lincoln and Hermjakob, Henning},
	month = mar,
	year = {2017},
	pages = {142},
}

@article{frazier_tutorial_2018,
	title = {A {Tutorial} on {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1807.02811},
	abstract = {Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample. In this tutorial, we describe how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-fidelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. We conclude with a discussion of Bayesian optimization software and future research directions in the field. Within our tutorial material we provide a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justified by a formal decision-theoretic argument, standing in contrast to previous ad hoc modifications.},
	urldate = {2021-02-07},
	journal = {arXiv:1807.02811 [cs, math, stat]},
	author = {Frazier, Peter I.},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.02811},
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Gaussian processes for machine learning},
	isbn = {978-0-262-18253-9},
	language = {en},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
}

@article{snoek_practical_nodate,
	title = {Practical {Bayesian} {Optimization} of {Machine} {Learning} {Algorithms}},
	abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes bruteforce search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
	language = {en},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	pages = {9},
}

@article{binder_layer-wise_2016,
	title = {Layer-wise {Relevance} {Propagation} for {Neural} {Networks} with {Local} {Renormalization} {Layers}},
	url = {http://arxiv.org/abs/1604.00825},
	abstract = {Layer-wise relevance propagation is a framework which allows to decompose the prediction of a deep neural network computed over a sample, e.g. an image, down to relevance scores for the single input dimensions of the sample such as subpixels of an image. While this approach can be applied directly to generalized linear mappings, product type non-linearities are not covered. This paper proposes an approach to extend layer-wise relevance propagation to neural networks with local renormalization layers, which is a very common product-type non-linearity in convolutional neural networks. We evaluate the proposed method for local renormalization layers on the CIFAR-10, Imagenet and MIT Places datasets.},
	urldate = {2021-01-19},
	journal = {arXiv:1604.00825 [cs]},
	author = {Binder, Alexander and Montavon, Grégoire and Bach, Sebastian and Müller, Klaus-Robert and Samek, Wojciech},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.00825},
}

@article{shrikumar_not_2017,
	title = {Not {Just} a {Black} {Box}: {Learning} {Important} {Features} {Through} {Propagating} {Activation} {Differences}},
	shorttitle = {Not {Just} a {Black} {Box}},
	url = {http://arxiv.org/abs/1605.01713},
	abstract = {Note: This paper describes an older version of DeepLIFT. See https://arxiv.org/abs/1704.02685 for the newer version. Original abstract follows: The purported "black box" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Learning Important FeaTures), an efficient and effective method for computing importance scores in a neural network. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. We apply DeepLIFT to models trained on natural images and genomic data, and show significant advantages over gradient-based methods.},
	urldate = {2021-01-19},
	journal = {arXiv:1605.01713 [cs]},
	author = {Shrikumar, Avanti and Greenside, Peyton and Shcherbina, Anna and Kundaje, Anshul},
	month = apr,
	year = {2017},
	note = {arXiv: 1605.01713},
}

@article{sundararajan_axiomatic_2017,
	title = {Axiomatic {Attribution} for {Deep} {Networks}},
	url = {http://arxiv.org/abs/1703.01365},
	abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisﬁed by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modiﬁcation to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	language = {en},
	urldate = {2021-01-19},
	journal = {arXiv:1703.01365 [cs]},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	month = jun,
	year = {2017},
	note = {arXiv: 1703.01365},
}

@article{baehrens_how_nodate,
	title = {How to {Explain} {Individual} {Classiﬁcation} {Decisions}},
	abstract = {After building a classiﬁer with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most inﬂuential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classiﬁcation method.},
	language = {en},
	author = {Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja},
	pages = {29},
}

@article{montavon_methods_2018,
	title = {Methods for interpreting and understanding deep neural networks},
	volume = {73},
	issn = {1051-2004},
	url = {http://www.sciencedirect.com/science/article/pii/S1051200417302385},
	doi = {10.1016/j.dsp.2017.10.011},
	abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data.},
	language = {en},
	urldate = {2021-01-19},
	journal = {Digital Signal Processing},
	author = {Montavon, Grégoire and Samek, Wojciech and Müller, Klaus-Robert},
	month = feb,
	year = {2018},
	pages = {1--15},
}

@article{galar_review_2012,
	title = {A {Review} on {Ensembles} for the {Class} {Imbalance} {Problem}: {Bagging}-, {Boosting}-, and {Hybrid}-{Based} {Approaches}},
	volume = {42},
	issn = {1558-2442},
	shorttitle = {A {Review} on {Ensembles} for the {Class} {Imbalance} {Problem}},
	doi = {10.1109/TSMCC.2011.2161285},
	abstract = {Classifier learning with data-sets that suffer from imbalanced class distributions is a challenging problem in data mining community. This issue occurs when the number of examples that represent one class is much lower than the ones of the other classes. Its presence in many real-world applications has brought along a growth of attention from researchers. In machine learning, the ensemble of classifiers are known to increase the accuracy of single classifiers by combining several of them, but neither of these learning techniques alone solve the class imbalance problem, to deal with this issue the ensemble learning algorithms have to be designed specifically. In this paper, our aim is to review the state of the art on ensemble techniques in the framework of imbalanced data-sets, with focus on two-class problems. We propose a taxonomy for ensemble-based methods to address the class imbalance where each proposal can be categorized depending on the inner ensemble methodology in which it is based. In addition, we develop a thorough empirical comparison by the consideration of the most significant published approaches, within the families of the taxonomy proposed, to show whether any of them makes a difference. This comparison has shown the good behavior of the simplest approaches which combine random undersampling techniques with bagging or boosting ensembles. In addition, the positive synergy between sampling techniques and bagging has stood out. Furthermore, our results show empirically that ensemble-based algorithms are worthwhile since they outperform the mere use of preprocessing techniques before learning the classifier, therefore justifying the increase of complexity by means of a significant enhancement of the results.},
	number = {4},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Galar, M. and Fernandez, A. and Barrenechea, E. and Bustince, H. and Herrera, F.},
	month = jul,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	pages = {463--484},
}

@article{sechidis_stratication_nodate,
	title = {On the {Stratiﬁcation} of {Multi}-{Label} {Data}},
	abstract = {Stratiﬁed sampling is a sampling method that takes into account the existence of disjoint groups within a population and produces samples where the proportion of these groups is maintained. In single-label classiﬁcation tasks, groups are diﬀerentiated based on the value of the target variable. In multi-label learning tasks, however, where there are multiple target variables, it is not clear how stratiﬁed sampling could/should be performed. This paper investigates stratiﬁcation in the multi-label data context. It considers two stratiﬁcation methods for multi-label data and empirically compares them along with random sampling on a number of datasets and based on a number of evaluation criteria. The results reveal some interesting conclusions with respect to the utility of each method for particular types of multi-label datasets.},
	language = {en},
	author = {Sechidis, Konstantinos and Tsoumakas, Grigorios and Vlahavas, Ioannis},
	pages = {15},
}

@article{schaffer_selecting_1993,
	title = {Selecting a classification method by cross-validation},
	volume = {13},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00993106},
	doi = {10.1007/BF00993106},
	abstract = {If we lack relevant problem-specific knowledge, cross-validation methods may be used to select a classification method empirically. We examine this idea here to show in what senses cross-validation does and does not solve the selection problem. As illustrated empirically, cross-validation may lead to higher average performance than application of any single classification strategy, and it also cuts the risk of poor performance. On the other hand, cross-validation is no more or less a form of bias than simpler strategies, and applying it appropriately ultimately depends in the same way on prior knowledge. In fact, cross-validation may be seen as a way of applying partial information about the applicability of alternative classification strategies.},
	language = {en},
	number = {1},
	urldate = {2021-01-13},
	journal = {Machine Learning},
	author = {Schaffer, Cullen},
	month = oct,
	year = {1993},
	pages = {135--143},
}

@misc{noauthor_drug_nodate,
	title = {Drug {Repurposing} {Using} {Deep} {Embeddings} of {Gene} {Expression} {Profiles} {\textbar} {Molecular} {Pharmaceutics}},
	url = {https://pubs.acs.org/doi/10.1021/acs.molpharmaceut.8b00284},
	urldate = {2021-01-06},
}

@article{ravindranath_connecting_2015,
	title = {Connecting gene expression data from connectivity map and in silico target predictions for small molecule mechanism-of-action analysis},
	volume = {11},
	issn = {1742-206X, 1742-2051},
	url = {http://xlink.rsc.org/?DOI=C4MB00328D},
	doi = {10.1039/C4MB00328D},
	abstract = {Integrating gene expression profiles with certain proteins can improve our understanding of the fundamental mechanisms in protein–ligand binding.
          , 
            
              Integrating gene expression profiles with certain proteins can improve our understanding of the fundamental mechanisms in protein–ligand binding. This paper spotlights the integration of gene expression data and target prediction scores, providing insight into mechanism of action (MoA). Compounds are clustered based upon the similarity of their predicted protein targets and each cluster is linked to gene sets using Linear Models for Microarray Data. MLP analysis is used to generate gene sets based upon their biological processes and a qualitative search is performed on the homogeneous target-based compound clusters to identify pathways. Genes and proteins were linked through pathways for 6 of the 8 MCF7 and 6 of the 11 PC3 clusters. Three compound clusters are studied; (i) the target-driven cluster involving HSP90 inhibitors, geldanamycin and tanespimycin induces differential expression for HSP90-related genes and overlap with pathway response to unfolded protein. Gene expression results are in agreement with target prediction and pathway annotations add information to enable understanding of MoA. (ii) The antipsychotic cluster shows differential expression for genes LDLR and INSIG-1 and is predicted to target CYP2D6. Pathway steroid metabolic process links the protein and respective genes, hypothesizing the MoA for antipsychotics. A sub-cluster (verepamil and dexverepamil), although sharing similar protein targets with the antipsychotic drug cluster, has a lower intensity of expression profile on related genes, indicating that this method distinguishes close sub-clusters and suggests differences in their MoA. Lastly, (iii) the thiazolidinediones drug cluster predicted peroxisome proliferator activated receptor (PPAR) PPAR-alpha, PPAR-gamma, acyl CoA desaturase and significant differential expression of genes ANGPTL4, FABP4 and PRKCD. The targets and genes are linked
              via
              PPAR signalling pathway and induction of apoptosis, generating a hypothesis for the MoA of thiazolidinediones. Our analysis show one or more underlying MoA for compounds and were well-substantiated with literature.},
	language = {en},
	number = {1},
	urldate = {2021-01-06},
	journal = {Molecular BioSystems},
	author = {Ravindranath, Aakash Chavan and Perualila-Tan, Nolen and Kasim, Adetayo and Drakakis, Georgios and Liggi, Sonia and Brewerton, Suzanne C. and Mason, Daniel and Bodkin, Michael J. and Evans, David A. and Bhagwat, Aditya and Talloen, Willem and Göhlmann, Hinrich W. H. and QSTAR Consortium, QSTAR Consortium and Shkedy, Ziv and Bender, Andreas},
	year = {2015},
	pages = {86--96},
}

@article{feng_padme_2019,
	title = {{PADME}: {A} {Deep} {Learning}-based {Framework} for {Drug}-{Target} {Interaction} {Prediction}},
	shorttitle = {{PADME}},
	url = {http://arxiv.org/abs/1807.09741},
	abstract = {In silico drug-target interaction (DTI) prediction is an important and challenging problem in biomedical research with a huge potential benefit to the pharmaceutical industry and patients. Most existing methods for DTI prediction including deep learning models generally have binary endpoints, which could be an oversimplification of the problem, and those methods are typically unable to handle cold-target problems, i.e., problems involving target protein that never appeared in the training set. Towards this, we contrived PADME (Protein And Drug Molecule interaction prEdiction), a framework based on Deep Neural Networks, to predict real-valued interaction strength between compounds and proteins without requiring feature engineering. PADME takes both compound and protein information as inputs, so it is capable of solving cold-target (and cold-drug) problems. To our knowledge, we are the first to combine Molecular Graph Convolution (MGC) for compound featurization with protein descriptors for DTI prediction. We used multiple cross-validation split schemes and evaluation metrics to measure the performance of PADME on multiple datasets, including the ToxCast dataset, and PADME consistently dominates baseline methods. The results of a case study, which predicts the binding affinity between various compounds and androgen receptor (AR), suggest PADME's potential in drug development. The scalability of PADME is another advantage in the age of Big Data.},
	urldate = {2021-01-06},
	journal = {arXiv:1807.09741 [cs, stat]},
	author = {Feng, Qingyuan and Dueva, Evgenia and Cherkasov, Artem and Ester, Martin},
	month = aug,
	year = {2019},
	note = {arXiv: 1807.09741},
}

@article{leitao_predicting_nodate,
	title = {Predicting {Eye} {Fixations} with a {Deep} {Reconstruction}-{Based} {Approach}},
	language = {en},
	author = {Leitao, Francisco},
	keywords = {type: example dissertation},
	pages = {63},
}

@article{szalai_signatures_2019,
	title = {Signatures of cell death and proliferation in perturbation transcriptomics data—from confounding factor to effective prediction},
	volume = {47},
	issn = {0305-1048},
	url = {https://doi.org/10.1093/nar/gkz805},
	doi = {10.1093/nar/gkz805},
	abstract = {Transcriptional perturbation signatures are valuable data sources for functional genomics. Linking perturbation signatures to screenings opens the possibility to model cellular phenotypes from expression data and to identify efficacious drugs. We linked perturbation transcriptomics data from the LINCS-L1000 project with cell viability information upon genetic (Achilles project) and chemical (CTRP screen) perturbations yielding more than 90 000 signature–viability pairs. An integrated analysis showed that the cell viability signature is a major factor underlying perturbation signatures. The signature is linked to transcription factors regulating cell death, proliferation and division time. We used the cell viability–signature relationship to predict viability from transcriptomics signatures, and identified and validated compounds that induce cell death in tumor cell lines. We showed that cellular toxicity can lead to unexpected similarity of signatures, confounding mechanism of action discovery. Consensus compound signatures predicted cell-specific drug sensitivity, even if the signature is not measured in the same cell line, and outperformed conventional drug-specific features. Our results can help in understanding mechanisms behind cell death and removing confounding factors of transcriptomic perturbation screens. To interactively browse our results and predict cell viability in new gene expression samples, we developed CEVIChE (CEll VIability Calculator from gene Expression; https://saezlab.shinyapps.io/ceviche/).},
	number = {19},
	urldate = {2021-01-03},
	journal = {Nucleic Acids Research},
	author = {Szalai, Bence and Subramanian, Vigneshwari and Holland, Christian H and Alföldi, Róbert and Puskás, László G and Saez-Rodriguez, Julio},
	month = nov,
	year = {2019},
	pages = {10010--10026},
}

@article{ragoza_proteinligand_2017,
	title = {Protein–{Ligand} {Scoring} with {Convolutional} {Neural} {Networks}},
	volume = {57},
	issn = {1549-9596},
	url = {https://doi.org/10.1021/acs.jcim.6b00740},
	doi = {10.1021/acs.jcim.6b00740},
	abstract = {Computational approaches to drug discovery can reduce the time and cost associated with experimental assays and enable the screening of novel chemotypes. Structure-based drug design methods rely on scoring functions to rank and predict binding affinities and poses. The ever-expanding amount of protein–ligand binding and structural data enables the use of deep machine learning techniques for protein–ligand scoring. We describe convolutional neural network (CNN) scoring functions that take as input a comprehensive three-dimensional (3D) representation of a protein–ligand interaction. A CNN scoring function automatically learns the key features of protein–ligand interactions that correlate with binding. We train and optimize our CNN scoring functions to discriminate between correct and incorrect binding poses and known binders and nonbinders. We find that our CNN scoring function outperforms the AutoDock Vina scoring function when ranking poses both for pose prediction and virtual screening.},
	number = {4},
	urldate = {2020-12-19},
	journal = {Journal of Chemical Information and Modeling},
	author = {Ragoza, Matthew and Hochuli, Joshua and Idrobo, Elisa and Sunseri, Jocelyn and Koes, David Ryan},
	month = apr,
	year = {2017},
	note = {Publisher: American Chemical Society},
	pages = {942--957},
}

@misc{noauthor_datasette_nodate,
	title = {Datasette: {An} open source multi-tool for exploring and publishing data},
	url = {https://datasette.io/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav},
	urldate = {2020-12-19},
}

@article{feng_padme_2019-1,
	title = {{PADME}: {A} {Deep} {Learning}-based {Framework} for {Drug}-{Target} {Interaction} {Prediction}},
	shorttitle = {{PADME}},
	url = {http://arxiv.org/abs/1807.09741},
	abstract = {In silico drug-target interaction (DTI) prediction is an important and challenging problem in biomedical research with a huge potential benefit to the pharmaceutical industry and patients. Most existing methods for DTI prediction including deep learning models generally have binary endpoints, which could be an oversimplification of the problem, and those methods are typically unable to handle cold-target problems, i.e., problems involving target protein that never appeared in the training set. Towards this, we contrived PADME (Protein And Drug Molecule interaction prEdiction), a framework based on Deep Neural Networks, to predict real-valued interaction strength between compounds and proteins without requiring feature engineering. PADME takes both compound and protein information as inputs, so it is capable of solving cold-target (and cold-drug) problems. To our knowledge, we are the first to combine Molecular Graph Convolution (MGC) for compound featurization with protein descriptors for DTI prediction. We used multiple cross-validation split schemes and evaluation metrics to measure the performance of PADME on multiple datasets, including the ToxCast dataset, and PADME consistently dominates baseline methods. The results of a case study, which predicts the binding affinity between various compounds and androgen receptor (AR), suggest PADME's potential in drug development. The scalability of PADME is another advantage in the age of Big Data.},
	urldate = {2020-12-19},
	journal = {arXiv:1807.09741 [cs, stat]},
	author = {Feng, Qingyuan and Dueva, Evgenia and Cherkasov, Artem and Ester, Martin},
	month = aug,
	year = {2019},
	note = {arXiv: 1807.09741},
}

@inproceedings{jaques_sequence_2017,
	title = {Sequence {Tutor}: {Conservative} {Fine}-{Tuning} of {Sequence} {Generation} {Models} with {KL}-control},
	shorttitle = {Sequence {Tutor}},
	url = {http://proceedings.mlr.press/v70/jaques17a.html},
	abstract = {This paper proposes a general method for improving the structure and quality of sequences generated by a recurrent neural network (RNN), while maintaining information originally learned from data, ...},
	language = {en},
	urldate = {2020-12-19},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Jaques, Natasha and Gu, Shixiang and Bahdanau, Dzmitry and Hernández-Lobato, José Miguel and Turner, Richard E. and Eck, Douglas},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {1645--1654},
}

@article{gomez-bombarelli_automatic_2018,
	title = {Automatic chemical design using a data-driven continuous representation of molecules},
	volume = {4},
	issn = {2374-7943, 2374-7951},
	url = {http://arxiv.org/abs/1610.02415},
	doi = {10.1021/acscentsci.7b00572},
	abstract = {We report a method to convert discrete representations of molecules to and from a multidimensional continuous representation. This model allows us to generate new molecules for efficient exploration and optimization through open-ended spaces of chemical compounds. A deep neural network was trained on hundreds of thousands of existing chemical structures to construct three coupled functions: an encoder, a decoder and a predictor. The encoder converts the discrete representation of a molecule into a real-valued continuous vector, and the decoder converts these continuous vectors back to discrete molecular representations. The predictor estimates chemical properties from the latent continuous vector representation of the molecule. Continuous representations allow us to automatically generate novel chemical structures by performing simple operations in the latent space, such as decoding random vectors, perturbing known chemical structures, or interpolating between molecules. Continuous representations also allow the use of powerful gradient-based optimization to efficiently guide the search for optimized functional compounds. We demonstrate our method in the domain of drug-like molecules and also in the set of molecules with fewer that nine heavy atoms.},
	number = {2},
	urldate = {2020-12-18},
	journal = {ACS Central Science},
	author = {Gómez-Bombarelli, Rafael and Wei, Jennifer N. and Duvenaud, David and Hernández-Lobato, José Miguel and Sánchez-Lengeling, Benjamín and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and Aspuru-Guzik, Alán},
	month = feb,
	year = {2018},
	note = {arXiv: 1610.02415},
	pages = {268--276},
}

@article{iorio_semi-supervised_2015,
	title = {A {Semi}-{Supervised} {Approach} for {Refining} {Transcriptional} {Signatures} of {Drug} {Response} and {Repositioning} {Predictions}},
	volume = {10},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0139446},
	doi = {10.1371/journal.pone.0139446},
	abstract = {We present a novel strategy to identify drug-repositioning opportunities. The starting point of our method is the generation of a signature summarising the consensual transcriptional response of multiple human cell lines to a compound of interest (namely the seed compound). This signature can be derived from data in existing databases, such as the connectivity-map, and it is used at first instance to query a network interlinking all the connectivity-map compounds, based on the similarity of their transcriptional responses. This provides a drug neighbourhood, composed of compounds predicted to share some effects with the seed one. The original signature is then refined by systematically reducing its overlap with the transcriptional responses induced by drugs in this neighbourhood that are known to share a secondary effect with the seed compound. Finally, the drug network is queried again with the resulting refined signatures and the whole process is carried on for a number of iterations. Drugs in the final refined neighbourhood are then predicted to exert the principal mode of action of the seed compound. We illustrate our approach using paclitaxel (a microtubule stabilising agent) as seed compound. Our method predicts that glipizide and splitomicin perturb microtubule function in human cells: a result that could not be obtained through standard signature matching methods. In agreement, we find that glipizide and splitomicin reduce interphase microtubule growth rates and transiently increase the percentage of mitotic cells–consistent with our prediction. Finally, we validated the refined signatures of paclitaxel response by mining a large drug screening dataset, showing that human cancer cell lines whose basal transcriptional profile is anti-correlated to them are significantly more sensitive to paclitaxel and docetaxel.},
	language = {en},
	number = {10},
	urldate = {2020-11-30},
	journal = {PLOS ONE},
	author = {Iorio, Francesco and Shrestha, Roshan L. and Levin, Nicolas and Boilot, Viviane and Garnett, Mathew J. and Saez-Rodriguez, Julio and Draviam, Viji M.},
	month = oct,
	year = {2015},
	note = {Publisher: Public Library of Science},
	pages = {e0139446},
}

@article{jin_ecmarker_2020,
	title = {{ECMarker}: {Interpretable} machine learning model identifies gene expression biomarkers predicting clinical outcomes and reveals molecular mechanisms of human disease in early stages},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	shorttitle = {{ECMarker}},
	url = {https://www.biorxiv.org/content/10.1101/825414v3},
	doi = {10.1101/825414},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Gene expression and regulation, a key molecular mechanism driving human disease development, remains elusive, especially at early stages. Integrating the increasing amount of population-level genomic data and understanding gene regulatory mechanisms in disease development are still challenging. Machine learning has emerged to solve this, but many machine learning methods were typically limited to building an accurate prediction model as a “black box”, barely providing biological and clinical interpretability from the box. To address these challenges, we developed an interpretable and scalable machine learning model, ECMarker, to predict gene expression biomarkers for disease phenotypes and simultaneously reveal underlying regulatory mechanisms. Particularly, ECMarker is built on the integration of semi- and discriminative- restricted Boltzmann machines, a neural network model for classification allowing lateral connections at the input gene layer. This interpretable model is scalable without needing any prior feature selection and enables directly modeling and prioritizing genes and revealing potential gene networks (from lateral connections) for the phenotypes. With application to the gene expression data of non-small cell lung cancer (NSCLC) patients, we found that ECMarker not only achieved a relatively high accuracy for predicting cancer stages but also identified the biomarker genes and gene networks implying the regulatory mechanisms in the lung cancer development. Additionally, ECMarker demonstrates clinical interpretability as its prioritized biomarker genes can predict survival rates of early lung cancer patients (\textit{p}-value \&lt; 0.005). Finally, we identified a number of drugs currently in clinical use for late stages or other cancers with effects on these early lung cancer biomarkers, suggesting potential novel candidates on early cancer medicine. ECMarker is open source as a general-purpose tool at https://github.com/daifengwanglab/ECMarker.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-11-23},
	journal = {bioRxiv},
	author = {Jin, Ting and Nguyen, Nam D. and Talos, Flaminia and Wang, Daifeng},
	month = jun,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {825414},
}

@techreport{lapins_evaluation_2019,
	type = {preprint},
	title = {Evaluation of {Gene} {Expression} and {Phenotypic} {Profiling} {Data} as {Quantitative} {Descriptors} for {Predicting} {Drug} {Targets} and {Mechanisms} of {Action}},
	url = {http://biorxiv.org/lookup/doi/10.1101/580654},
	abstract = {Profiling drug leads by means of in silico and in vitro assays as well as omics is widely used in drug discovery for safety and efficacy predictions. In this study, we evaluate the performances of machine learning models trained on data from gene expression and phenotypic profiling assays, with in vitro assays by means of chemical structure descriptors, for prediction of various drug mechanisms of action and target proteins. Models for several hundred mechanism(s) of actions and protein targets were trained using data on 1484 compounds characterized in both gene expression using L1000 profiles, and phenotypic profiling with cell painting assays. The results indicate that the accuracy of the three profiling technologies varies for different endpoints, and indicate a clear potential synergistic effect if these methods are combined. We also study the effect of predictive accuracy of data from different cell lines for L1000 profiles, showing that the choice of cell line has a non-negligible effect on the predictive accuracy. The results strengthens the idea of integrated approaches for predicting drug targets and mechanisms of action in preclinical drug discovery.},
	language = {en},
	urldate = {2020-11-23},
	institution = {Bioinformatics},
	author = {Lapins, Maris and Spjuth, Ola},
	month = mar,
	year = {2019},
	doi = {10.1101/580654},
}

@article{donner_drug_2018,
	title = {Drug {Repurposing} {Using} {Deep} {Embeddings} of {Gene} {Expression} {Profiles}},
	volume = {15},
	issn = {1543-8384},
	url = {https://doi.org/10.1021/acs.molpharmaceut.8b00284},
	doi = {10.1021/acs.molpharmaceut.8b00284},
	abstract = {Computational drug repositioning requires assessment of the functional similarities among compounds. Here, we report a new method for measuring compound functional similarity based on gene expression data. This approach takes advantage of deep neural networks to learn an embedding that substantially denoises expression data, making replicates of the same compound more similar. Our method uses unlabeled data in the sense that it only requires compounds to be labeled by identity rather than detailed pharmacological information, which is often unavailable and costly to obtain. Similarity in the learned embedding space accurately predicted pharmacological similarities despite the lack of any such labels during training and achieved substantially improved performance in comparison with previous similarity measures applied to gene expression measurements. Our method could identify drugs with shared therapeutic and biological targets even when the compounds were structurally dissimilar, thereby revealing previously unreported functional relationships between compounds. Thus, our approach provides an improved engine for drug repurposing based on expression data, which we have made available through the online tool DeepCodex (http://deepcodex.org).},
	number = {10},
	urldate = {2020-11-23},
	journal = {Molecular Pharmaceutics},
	author = {Donner, Yoni and Kazmierczak, Stéphane and Fortney, Kristen},
	month = oct,
	year = {2018},
	note = {Publisher: American Chemical Society},
	pages = {4314--4325},
}

@article{kalinin_deep_2018,
	title = {Deep {Learning} in {Pharmacogenomics}: {From} {Gene} {Regulation} to {Patient} {Stratification}},
	shorttitle = {Deep {Learning} in {Pharmacogenomics}},
	url = {http://arxiv.org/abs/1801.08570},
	doi = {10.2217/pgs-2018-0008},
	abstract = {This Perspective provides examples of current and future applications of deep learning in pharmacogenomics, including: (1) identification of novel regulatory variants located in noncoding domains and their function as applied to pharmacoepigenomics; (2) patient stratification from medical records; and (3) prediction of drugs, targets, and their interactions. Deep learning encapsulates a family of machine learning algorithms that over the last decade has transformed many important subfields of artificial intelligence (AI) and has demonstrated breakthrough performance improvements on a wide range of tasks in biomedicine. We anticipate that in the future deep learning will be widely used to predict personalized drug response and optimize medication selection and dosing, using knowledge extracted from large and complex molecular, epidemiological, clinical, and demographic datasets.},
	urldate = {2020-11-23},
	journal = {arXiv:1801.08570 [cs, q-bio, stat]},
	author = {Kalinin, Alexandr A. and Higgins, Gerald A. and Reamaroon, Narathip and Soroushmehr, S. M. Reza and Allyn-Feuer, Ari and Dinov, Ivo D. and Najarian, Kayvan and Athey, Brian D.},
	month = mar,
	year = {2018},
	note = {arXiv: 1801.08570},
}

@article{david_applications_2019,
	title = {Applications of {Deep}-{Learning} in {Exploiting} {Large}-{Scale} and {Heterogeneous} {Compound} {Data} in {Industrial} {Pharmaceutical} {Research}},
	volume = {10},
	issn = {1663-9812},
	url = {https://www.frontiersin.org/articles/10.3389/fphar.2019.01303/full},
	doi = {10.3389/fphar.2019.01303},
	abstract = {In recent years, the development of high-throughput screening (HTS) technologies and their establishment in an industrialized environment has given scientists the possibility to test millions of molecules and profile them against a multitude of biological targets in a short period of time, generating data in a much faster pace and with a higher quality than before. Besides the structure activity data from traditional bioassays, more complex assays such as transcriptomics profiling or imaging have also been established as routine profiling experiments thanks to the advancement of Next Generation Sequencing or automated microscopy technologies. In industrial pharmaceutical research these technologies are typically established in conjunction with automated platforms in order to enable efficient handling of screening collections of thousands to millions of compounds. To exploit the ever-growing amount of data that is generated by these approaches, computational techniques are constantly evolving. In this regard, artificial intelligence technologies such as deep learning and machine learning methods play a key role in cheminformatics and bio-image analytics fields to address activity prediction, scaffold hopping, de novo molecule design, reaction/retrosynthesis predictions or high content screening analysis. Herein we summarize the current state of analysing large-scale compound data in industrial pharmaceutical research and describe the impact it has had on the drug discovery process over the last two decades, with a specific focus on artificial intelligence technologies.},
	language = {English},
	urldate = {2020-11-23},
	journal = {Frontiers in Pharmacology},
	author = {David, Laurianne and Arús-Pous, Josep and Karlsson, Johan and Engkvist, Ola and Bjerrum, Esben Jannik and Kogej, Thierry and Kriegl, Jan M. and Beck, Bernd and Chen, Hongming},
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {section:background, section:background/related work, topic: deep learning},
}

@misc{noauthor_ouci_nodate,
	title = {{OUCI}},
	url = {https://ouci.dntb.gov.ua/en/works/4ke0Oqm9/},
	abstract = {Open Ukrainian Citation Index (OUCI) is a search engine and a citation database based on publication metadata from Crossref members.},
	language = {uk-UA},
	urldate = {2020-11-23},
}

@article{lipinski_advances_2019,
	title = {Advances and {Perspectives} in {Applying} {Deep} {Learning} for {Drug} {Design} and {Discovery}},
	volume = {6},
	issn = {2296-9144},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2019.00108/full},
	doi = {10.3389/frobt.2019.00108},
	abstract = {Discovering (or planning) a new drug candidate involves many parameters, which makes this process slow, costly and leading to failures at the end in some cases. In the last decades, we have witnessed a revolution in the computational area (hardware, software, large-scale computing, etc.), as well as an explosion in data generation (big data), which raises the need for more sophisticated algorithms to analyze this myriad of data. In this scenario, we can highlight the potentialities of artificial intelligence (AI) or computational intelligence (CI) as a powerful tool to analyze medicinal chemistry data. According to IEEE, computational intelligence involves the theory, the design, the application and the development of biologically and linguistically motivated computational paradigms. In addition, CI encompasses three main methodologies: neural networks (NN), fuzzy systems and evolutionary computation. In particular, artificial neural networks have been successfully applied in medicinal chemistry studies. A branch of the NN area that has attracted a lot of attention refers to deep learning (DL) due to its generalization power and ability to extract features from data. Therefore, in this mini-review we will briefly outline the present scope, advances and challenges related to the use of DL in drug design and discovery, describing successful studies involving quantitative structure-activity relationships (QSAR) and virtual screening (VS) of databases containing thousands of compounds.},
	language = {English},
	urldate = {2020-11-20},
	journal = {Frontiers in Robotics and AI},
	author = {Lipinski, Celio F. and Maltarollo, Vinicius G. and Oliveira, Patricia R. and da Silva, Alberico B. F. and Honorio, Kathia Maria},
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {section:background/related work},
}

@article{siblini_review_2019,
	title = {A review on dimensionality reduction for multi-label classification},
	url = {https://hal.archives-ouvertes.fr/hal-02321656},
	doi = {10.1109/TKDE.2019.2940014},
	abstract = {Multi-label classification has gained in importance in the last decade and it is today confronted to the current needs to process massive raw data from heterogeneous sources. Therefore, dimensionality reduction, which aims at reducing the number of features, labels, or both, knows a renewed interest to enhance the scaling properties of the classifiers and their predictive performances. In this paper we review more than fifty papers presenting dimensionality reduction approaches for multi-label classification and we propose an analysis in three steps : (i) a typology of the methods describing the main components of their strategies, the problem they tackle and the way they solve it (ii) a unified formalization of the problems to help to distinguish the similarities and differences between the approaches, and (iii) a meta-analysis of the published experimental results inspired by the consensus theory to identify the most efficient algorithms.},
	urldate = {2020-11-20},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Siblini, Wissam and Kuntz, Pascale and Meyer, Frank},
	year = {2019},
	note = {Publisher: Institute of Electrical and Electronics Engineers},
	keywords = {topic: autoencoder/pca/dr},
}

@article{kusner_grammar_2017,
	title = {Grammar {Variational} {Autoencoder}},
	url = {http://arxiv.org/abs/1703.01925},
	abstract = {Deep generative models have been wildly successful at learning coherent latent representations for continuous data such as video and audio. However, generative modeling of discrete data such as arithmetic expressions and molecular structures still poses significant challenges. Crucially, state-of-the-art methods often produce outputs that are not valid. We make the key observation that frequently, discrete data can be represented as a parse tree from a context-free grammar. We propose a variational autoencoder which encodes and decodes directly to and from these parse trees, ensuring the generated outputs are always valid. Surprisingly, we show that not only does our model more often generate valid outputs, it also learns a more coherent latent space in which nearby points decode to similar discrete outputs. We demonstrate the effectiveness of our learned models by showing their improved performance in Bayesian optimization for symbolic regression and molecular synthesis.},
	urldate = {2020-11-19},
	journal = {arXiv:1703.01925 [stat]},
	author = {Kusner, Matt J. and Paige, Brooks and Hernández-Lobato, José Miguel},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.01925},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2020-11-18},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	note = {Number: 7553
Publisher: Nature Publishing Group},
	pages = {436--444},
}

@article{lecun_deep_2015-1,
	title = {Deep learning},
	volume = {521},
	issn = {1476-4687},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {eng},
	number = {7553},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pmid = {26017442},
	pages = {436--444},
}

@article{grada_next-generation_2013,
	title = {Next-{Generation} {Sequencing}: {Methodology} and {Application}},
	volume = {133},
	issn = {0022-202X, 1523-1747},
	shorttitle = {Next-{Generation} {Sequencing}},
	url = {https://www.jidonline.org/article/S0022-202X(15)36383-1/abstract},
	doi = {10.1038/jid.2013.248},
	abstract = {Nucleic acid sequencing is a method for determining the exact order of nucleotides
present in a given DNA or RNA molecule. In the past decade, the use of nucleic acid
sequencing has increased exponentially as the ability to sequence has become accessible
to research and clinical labs all over the world. The first major foray into DNA sequencing
was the Human Genome Project, a \$3 billion, 13-year-long endeavor, completed in 2003.
The Human Genome Project was accomplished with first-generation sequencing, known
as Sanger sequencing.},
	language = {English},
	number = {8},
	urldate = {2020-11-18},
	journal = {Journal of Investigative Dermatology},
	author = {Grada, Ayman and Weinbrecht, Kate},
	month = aug,
	year = {2013},
	pmid = {23299443},
	note = {Publisher: Elsevier},
	pages = {1--4},
}

@article{kim_pubchem_2016,
	title = {{PubChem} {Substance} and {Compound} databases},
	volume = {44},
	issn = {0305-1048},
	url = {https://academic.oup.com/nar/article/44/D1/D1202/2503131},
	doi = {10.1093/nar/gkv951},
	abstract = {Abstract. PubChem (https://pubchem.ncbi.nlm.nih.gov) is a public repository for information on chemical substances and their biological activities, launched in},
	language = {en},
	number = {D1},
	urldate = {2020-11-18},
	journal = {Nucleic Acids Research},
	author = {Kim, Sunghwan and Thiessen, Paul A. and Bolton, Evan E. and Chen, Jie and Fu, Gang and Gindulyte, Asta and Han, Lianyi and He, Jane and He, Siqian and Shoemaker, Benjamin A. and Wang, Jiyao and Yu, Bo and Zhang, Jian and Bryant, Stephen H.},
	month = jan,
	year = {2016},
	note = {Publisher: Oxford Academic},
	pages = {D1202--D1213},
}

@article{papadatos_activity_2015,
	title = {Activity, assay and target data curation and quality in the {ChEMBL} database},
	volume = {29},
	issn = {1573-4951},
	url = {https://doi.org/10.1007/s10822-015-9860-5},
	doi = {10.1007/s10822-015-9860-5},
	abstract = {The emergence of a number of publicly available bioactivity databases, such as ChEMBL, PubChem BioAssay and BindingDB, has raised awareness about the topics of data curation, quality and integrity. Here we provide an overview and discussion of the current and future approaches to activity, assay and target data curation of the ChEMBL database. This curation process involves several manual and automated steps and aims to: (1) maximise data accessibility and comparability; (2) improve data integrity and flag outliers, ambiguities and potential errors; and (3) add further curated annotations and mappings thus increasing the usefulness and accuracy of the ChEMBL data for all users and modellers in particular. Issues related to activity, assay and target data curation and integrity along with their potential impact for users of the data are discussed, alongside robust selection and filter strategies in order to avoid or minimise these, depending on the desired application.},
	language = {en},
	number = {9},
	urldate = {2020-11-18},
	journal = {Journal of Computer-Aided Molecular Design},
	author = {Papadatos, George and Gaulton, Anna and Hersey, Anne and Overington, John P.},
	month = sep,
	year = {2015},
	pages = {885--896},
}

@article{gaulton_chembl_2012,
	title = {{ChEMBL}: a large-scale bioactivity database for drug discovery},
	volume = {40},
	issn = {0305-1048},
	shorttitle = {{ChEMBL}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3245175/},
	doi = {10.1093/nar/gkr777},
	abstract = {ChEMBL is an Open Data database containing binding, functional and ADMET information for a large number of drug-like bioactive compounds. These data are manually abstracted from the primary published literature on a regular basis, then further curated and standardized to maximize their quality and utility across a wide range of chemical biology and drug-discovery research problems. Currently, the database contains 5.4 million bioactivity measurements for more than 1 million compounds and 5200 protein targets. Access is available through a web-based interface, data downloads and web services at: https://www.ebi.ac.uk/chembldb.},
	number = {Database issue},
	urldate = {2020-11-18},
	journal = {Nucleic Acids Research},
	author = {Gaulton, Anna and Bellis, Louisa J. and Bento, A. Patricia and Chambers, Jon and Davies, Mark and Hersey, Anne and Light, Yvonne and McGlinchey, Shaun and Michalovich, David and Al-Lazikani, Bissan and Overington, John P.},
	month = jan,
	year = {2012},
	pmid = {21948594},
	pmcid = {PMC3245175},
	pages = {D1100--D1107},
}

@article{glorot_understanding_nodate,
	title = {Understanding the difﬁculty of training deep feedforward neural networks},
	abstract = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We ﬁrst observe the inﬂuence of the non-linear activations functions. We ﬁnd that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we ﬁnd that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We ﬁnd that a new non-linearity that saturates less can often be beneﬁcial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difﬁcult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
	language = {en},
	author = {Glorot, Xavier and Bengio, Yoshua},
	pages = {8},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	copyright = {1986 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	language = {en},
	number = {6088},
	urldate = {2020-11-13},
	journal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	month = oct,
	year = {1986},
	note = {Number: 6088
Publisher: Nature Publishing Group},
	pages = {533--536},
}

@article{snoek_practical_nodate,
	title = {Practical {Bayesian} {Optimization} of {Machine} {Learning} {Algorithms}},
	abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes bruteforce search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
	language = {en},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	keywords = {section: methods, section:background, topic: bo optimization},
	pages = {9},
}

@article{smith_disciplined_2018,
	title = {A disciplined approach to neural network hyper-parameters: {Part} 1 -- learning rate, batch size, momentum, and weight decay},
	shorttitle = {A disciplined approach to neural network hyper-parameters},
	url = {http://arxiv.org/abs/1803.09820},
	abstract = {Although deep learning has produced dazzling successes for applications of image, speech, and video processing in the past few years, most trainings are with suboptimal hyper-parameters, requiring unnecessarily long training times. Setting the hyper-parameters remains a black art that requires years of experience to acquire. This report proposes several efficient ways to set the hyper-parameters that significantly reduce training time and improves performance. Specifically, this report shows how to examine the training validation/test loss function for subtle clues of underfitting and overfitting and suggests guidelines for moving toward the optimal balance point. Then it discusses how to increase/decrease the learning rate/momentum to speed up training. Our experiments show that it is crucial to balance every manner of regularization for each dataset and architecture. Weight decay is used as a sample regularizer to show how its optimal value is tightly coupled with the learning rates and momentums. Files to help replicate the results reported here are available.},
	urldate = {2020-11-09},
	journal = {arXiv:1803.09820 [cs, stat]},
	author = {Smith, Leslie N.},
	month = apr,
	year = {2018},
	note = {arXiv: 1803.09820},
	keywords = {section: methods, topic: bo optimization},
}

@article{frazier_tutorial_2018,
	title = {A {Tutorial} on {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1807.02811},
	abstract = {Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample. In this tutorial, we describe how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-fidelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. We conclude with a discussion of Bayesian optimization software and future research directions in the field. Within our tutorial material we provide a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justified by a formal decision-theoretic argument, standing in contrast to previous ad hoc modifications.},
	urldate = {2020-10-27},
	journal = {arXiv:1807.02811 [cs, math, stat]},
	author = {Frazier, Peter I.},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.02811},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning, topic: bo optimization},
}

@article{itadani_can_2008,
	title = {Can {Systems} {Biology} {Understand} {Pathway} {Activation}? {Gene} {Expression} {Signatures} as {Surrogate} {Markers} for {Understanding} the {Complexity} of {Pathway} {Activation}},
	volume = {9},
	issn = {1389-2029},
	shorttitle = {Can {Systems} {Biology} {Understand} {Pathway} {Activation}?},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2694555/},
	doi = {10.2174/138920208785133235},
	abstract = {Cancer is thought to be caused by a sequence of multiple genetic and epigenetic alterations which occur in one or more of the genes controlling cell cycle progression and signaling transduction. The complexity of carcinogenic mechanisms leads to heterogeneity in molecular phenotype, pathology, and prognosis of cancers., Genome-wide mutational analysis of cancer genes in individual tumors is the most direct way to elucidate the complex process of disease progression, although such high-throughput sequencing technologies are not yet fully developed. As a surrogate marker for pathway activation analysis, expression profiling using microarrays has been successfully applied for the classification of tumor types, stages of tumor progression, or in some cases, prediction of clinical outcomes. However, the biological implication of those gene expression signatures is often unclear. , Systems biological approaches leverage the signature genes as a representation of changes in signaling pathways, instead of interpreting the relevance between each gene and phenotype. This approach, which can be achieved by comparing the gene set or the expression profile with those of reference experiments in which a defined pathway is modulated, will improve our understanding of cancer classification, clinical outcome, and carcinogenesis. In this review, we will discuss recent studies on the development of expression signatures to monitor signaling pathway activities and how these signatures can be used to improve the identification of responders to anticancer drugs.},
	number = {5},
	urldate = {2020-11-01},
	journal = {Current Genomics},
	author = {Itadani, Hiraku and Mizuarai, Shinji and Kotani, Hidehito},
	month = aug,
	year = {2008},
	pmid = {19517027},
	pmcid = {PMC2694555},
	keywords = {section:background},
	pages = {349--360},
}

@article{musa_review_2017,
	title = {A review of connectivity map and computational approaches in pharmacogenomics},
	volume = {19},
	issn = {1467-5463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5952941/},
	doi = {10.1093/bib/bbw112},
	abstract = {Large-scale perturbation databases, such as Connectivity Map (CMap) or Library of Integrated Network-based Cellular Signatures (LINCS), provide enormous opportunities for computational pharmacogenomics and drug design. A reason for this is that in contrast to classical pharmacology focusing at one target at a time, the transcriptomics profiles provided by CMap and LINCS open the door for systems biology approaches on the pathway and network level. In this article, we provide a review of recent developments in computational pharmacogenomics with respect to CMap and LINCS and related applications.},
	number = {3},
	urldate = {2020-11-03},
	journal = {Briefings in Bioinformatics},
	author = {Musa, Aliyu and Ghoraie, Laleh Soltan and Zhang, Shu-Dong and Glazko, Galina and Yli-Harja, Olli and Dehmer, Matthias and Haibe-Kains, Benjamin and Emmert-Streib, Frank},
	month = jan,
	year = {2017},
	pmid = {28069634},
	pmcid = {PMC5952941},
	keywords = {section: motivation, section:background, topic: L1000 and Connectivity Map},
	pages = {506--523},
}

@article{lamb_connectivity_2006,
	title = {The {Connectivity} {Map}: {Using} {Gene}-{Expression} {Signatures} to {Connect} {Small} {Molecules}, {Genes}, and {Disease}},
	volume = {313},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	shorttitle = {The {Connectivity} {Map}},
	url = {https://science.sciencemag.org/content/313/5795/1929},
	doi = {10.1126/science.1132939},
	abstract = {To pursue a systematic approach to the discovery of functional connections among diseases, genetic perturbation, and drug action, we have created the first installment of a reference collection of gene-expression profiles from cultured human cells treated with bioactive small molecules, together with pattern-matching software to mine these data. We demonstrate that this “Connectivity Map” resource can be used to find connections among small molecules sharing a mechanism of action, chemicals and physiological processes, and diseases and drugs. These results indicate the feasibility of the approach and suggest the value of a large-scale community Connectivity Map project.
Comparison of mRNAs evoked by small molecules in human cells to mRNA expressed in diseases and in response to drugs suggests new therapeutic approaches.
Comparison of mRNAs evoked by small molecules in human cells to mRNA expressed in diseases and in response to drugs suggests new therapeutic approaches.},
	language = {en},
	number = {5795},
	urldate = {2020-11-03},
	journal = {Science},
	author = {Lamb, Justin and Crawford, Emily D. and Peck, David and Modell, Joshua W. and Blat, Irene C. and Wrobel, Matthew J. and Lerner, Jim and Brunet, Jean-Philippe and Subramanian, Aravind and Ross, Kenneth N. and Reich, Michael and Hieronymus, Haley and Wei, Guo and Armstrong, Scott A. and Haggarty, Stephen J. and Clemons, Paul A. and Wei, Ru and Carr, Steven A. and Lander, Eric S. and Golub, Todd R.},
	month = sep,
	year = {2006},
	pmid = {17008526},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	keywords = {section: motivation, section:background, topic: L1000 and Connectivity Map},
	pages = {1929--1935},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2020-11-03},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
}

@book{alberts_essential_2013,
	address = {New York, NY},
	edition = {Fourth edition},
	title = {Essential cell biology},
	isbn = {978-0-8153-4454-4 978-0-8153-4455-1},
	publisher = {Garland Science},
	author = {Alberts, Bruce},
	year = {2013},
}

@book{blitzstein_introduction_2015,
	address = {Boca Raton},
	series = {Texts in statistical science},
	title = {Introduction to probability},
	isbn = {978-1-4665-7557-8},
	publisher = {CRC Press/Taylor \& Francis Group},
	author = {Blitzstein, Joseph K. and Hwang, Jessica},
	year = {2015},
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	language = {en},
	number = {5},
	urldate = {2020-11-03},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	month = jan,
	year = {1989},
	pages = {359--366},
}

@article{scannell_diagnosing_2012,
	title = {Diagnosing the decline in pharmaceutical {R}\&{D} efficiency},
	volume = {11},
	issn = {1474-1776, 1474-1784},
	url = {http://www.nature.com/articles/nrd3681},
	doi = {10.1038/nrd3681},
	language = {en},
	number = {3},
	urldate = {2020-11-02},
	journal = {Nature Reviews Drug Discovery},
	author = {Scannell, Jack W. and Blanckley, Alex and Boldon, Helen and Warrington, Brian},
	month = mar,
	year = {2012},
	pages = {191--200},
}

@article{paul_how_2010,
	title = {How to improve {R}\&{D} productivity: the pharmaceutical industry's grand challenge},
	volume = {9},
	copyright = {2010 Nature Publishing Group},
	issn = {1474-1784},
	shorttitle = {How to improve {R}\&{D} productivity},
	url = {https://www.nature.com/articles/nrd3078},
	doi = {10.1038/nrd3078},
	abstract = {The biopharmaceutical industry is facing unprecedented challenges to its fundamental business model and currently cannot sustain sufficient innovation to replace its products and revenues lost due to patent expirations.The number of truly innovative new medicines approved by regulatory agencies such as the US Food and Drug Administration has declined substantially despite continued increases in R\&D spending, raising the current cost of each new molecular entity (NME) to approximately US\$1.8 billionDeclining R\&D productivity is arguably the most important challenge the industry faces and thus improving R\&D productivity is its most important priority.A detailed analysis of the key elements that determine overall R\&D productivity and the cost to successfully develop an NME reveals exactly where (and to what degree) R\&D productivity can (and must) be improved.Reducing late-stage (Phase II and III) attrition rates and cycle times during drug development are among the key requirements for improving R\&D productivity.To achieve the necessary increase in R\&D productivity, R\&D investments, both financial and intellectual, must be focused on the 'sweet spot' of drug discovery and early clinical development, from target selection to clinical proof-of-concept.The transformation from a traditional biopharmaceutical FIPCo (fully integrated pharmaceutical company) to a FIPNet (fully integrated pharmaceutical network) should allow a given R\&D organization to 'play bigger than its size' and to more affordably fund the necessary number and quality of pipeline assets.},
	language = {en},
	number = {3},
	urldate = {2020-11-02},
	journal = {Nature Reviews Drug Discovery},
	author = {Paul, Steven M. and Mytelka, Daniel S. and Dunwiddie, Christopher T. and Persinger, Charles C. and Munos, Bernard H. and Lindborg, Stacy R. and Schacht, Aaron L.},
	month = mar,
	year = {2010},
	note = {Number: 3
Publisher: Nature Publishing Group},
	keywords = {section: motivation},
	pages = {203--214},
}

@misc{noauthor_diagnosing_nodate,
	title = {Diagnosing the decline in pharmaceutical {R}\&{D} efficiency {\textbar} {Nature} {Reviews} {Drug} {Discovery}},
	url = {https://www.nature.com/articles/nrd3681},
	urldate = {2020-11-02},
	keywords = {section: motivation, topic: drug discovery},
}

@article{jaeger_causal_2014,
	title = {Causal {Network} {Models} for {Predicting} {Compound} {Targets} and {Driving} {Pathways} in {Cancer}},
	volume = {19},
	issn = {1087-0571},
	url = {https://doi.org/10.1177/1087057114522690},
	doi = {10.1177/1087057114522690},
	abstract = {Gene-expression data are often used to infer pathways regulating transcriptional responses. For example, differentially expressed genes (DEGs) induced by compound treatment can help characterize hits from phenotypic screens, either by correlation with known drug signatures or by pathway enrichment. Pathway enrichment is, however, typically computed with DEGs rather than ?upstream? nodes that are potentially causal of ?downstream? changes. Here, we present graph-based models to predict causal targets from compound-microarray data. We test several approaches to traversing network topology, and show that a consensus minimum-rank score (SigNet) beat individual methods and could highly rank compound targets among all network nodes. In addition, larger, less canonical networks outperformed linear canonical interactions. Importantly, pathway enrichment using causal nodes rather than DEGs recovers relevant pathways more often. To further validate our approach, we used integrated data sets from the Cancer Genome Atlas to identify driving pathways in triple-negative breast cancer. Critical pathways were uncovered, including the epidermal growth factor receptor 2?phosphatidylinositide 3-kinase?AKT?MAPK growth pathway and ATR?p53?BRCA DNA damage pathway, in addition to unexpected pathways, such as TGF?WNT cytoskeleton remodeling, IL12-induced interferon gamma production, and TNFR?IAP (inhibitor of apoptosis) apoptosis; the latter was validated by pooled small hairpin RNA profiling in cancer cells. Overall, our approach can bridge transcriptional profiles to compound targets and driving pathways in cancer.},
	number = {5},
	urldate = {2020-11-01},
	journal = {Journal of Biomolecular Screening},
	author = {Jaeger, Savina and Min, Junxia and Nigsch, Florian and Camargo, Miguel and Hutz, Janna and Cornett, Allen and Cleaver, Stephen and Buckler, Alan and Jenkins, Jeremy L.},
	month = jun,
	year = {2014},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {791--802},
}

@article{marekova_zerovote_nodate,
	title = {Zerovote: {Self}-tallying {E}-voting {Protocol} in the {UC} {Framework}},
	abstract = {The main purpose of the project is to deﬁne a decentralized e-voting protocol that could be implemented on the blockchain in the universal composition (UC) framework and provide a formal proof that it preserves voter privacy.},
	language = {en},
	author = {Marekova, Lenka},
	keywords = {type: example dissertation},
	pages = {82},
}

@article{gifford_zen_nodate,
	title = {The {Zen} of {PCA}, t-{SNE}, and {Autoencoders}},
	language = {en},
	author = {Gifford, David},
	pages = {81},
}

@article{crick_protein_1958,
	title = {On protein synthesis},
	volume = {12},
	issn = {0081-1386},
	language = {eng},
	journal = {Symposia of the Society for Experimental Biology},
	author = {Crick, F. H.},
	year = {1958},
	pmid = {13580867},
	pages = {138--163},
}

@article{wehling_assessing_2009,
	title = {Assessing the translatability of drug projects: what needs to be scored to predict success?},
	volume = {8},
	copyright = {2009 Nature Publishing Group},
	issn = {1474-1784},
	shorttitle = {Assessing the translatability of drug projects},
	url = {https://www.nature.com/articles/nrd2898},
	doi = {10.1038/nrd2898},
	abstract = {More effective prediction of 'translational success' could have a key role in addressing the widely acknowledged problems with weak drug development pipelines. This article discusses how establishing a scoring system to systematically assess key determinants of translational success, such as biomarkers and animal and human data, could help achieve this goal.},
	language = {en},
	number = {7},
	urldate = {2020-10-31},
	journal = {Nature Reviews Drug Discovery},
	author = {Wehling, Martin},
	month = jul,
	year = {2009},
	note = {Number: 7
Publisher: Nature Publishing Group},
	pages = {541--546},
}

@article{kascenas_font_nodate,
	title = {Font {Style} {Transfer} {Using} {Deep} {Learning}},
	abstract = {Font style transfer is a task of inferring a font style from a set of characters and generating a different set of characters exhibiting the inferred style. Font style transfer is a generalisation of a problem of ﬁlling in fonts that do not deﬁne certain characters.},
	language = {en},
	author = {Kascenas, Antanas},
	keywords = {type: example dissertation},
	pages = {60},
}

@article{xie_discovery_2017,
	title = {Discovery of novel therapeutic properties of drugs from transcriptional responses based on multi-label classification},
	volume = {7},
	issn = {2045-2322},
	doi = {10.1038/s41598-017-07705-8},
	abstract = {Drug repositioning strategies have improved substantially in recent years. At present, two advances are poised to facilitate new strategies. First, the LINCS project can provide rich transcriptome data that reflect the responses of cells upon exposure to various drugs. Second, machine learning algorithms have been applied successfully in biomedical research. In this paper, we developed a systematic method to discover novel indications for existing drugs by approaching drug repositioning as a multi-label classification task and used a Softmax regression model to predict previously unrecognized therapeutic properties of drugs based on LINCS transcriptome data. This approach to complete the said task has not been achieved in previous studies. By performing in silico comparison, we demonstrated that the proposed Softmax method showed markedly superior performance over those of other methods. Once fully trained, the method showed a training accuracy exceeding 80\% and a validation accuracy of approximately 70\%. We generated a highly credible set of 98 drugs with high potential to be repositioned for novel therapeutic purposes. Our case studies included zonisamide and brinzolamide, which were originally developed to treat indications of the nervous system and sensory organs, respectively. Both drugs were repurposed to the cardiovascular category.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Xie, Lingwei and He, Song and Wen, Yuqi and Bo, Xiaochen and Zhang, Zhongnan},
	year = {2017},
	pmid = {28769090},
	pmcid = {PMC5541064},
	keywords = {Algorithms, Drug Discovery, Drug Repositioning, Gene Expression Profiling, Humans, Reproducibility of Results, Transcription, Genetic},
	pages = {7136},
}

@article{corsello_discovering_2020,
	title = {Discovering the anticancer potential of non-oncology drugs by systematic viability profiling},
	volume = {1},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {2662-1347},
	url = {https://www.nature.com/articles/s43018-019-0018-6},
	doi = {10.1038/s43018-019-0018-6},
	abstract = {Anticancer uses of non-oncology drugs have occasionally been found, but such discoveries have been serendipitous. We sought to create a public resource containing the growth-inhibitory activity of 4,518 drugs tested across 578 human cancer cell lines. We used PRISM (profiling relative inhibition simultaneously in mixtures), a molecular barcoding method, to screen drugs against cell lines in pools. An unexpectedly large number of non-oncology drugs selectively inhibited subsets of cancer cell lines in a manner predictable from the molecular features of the cell lines. Our findings include compounds that killed by inducing phosphodiesterase 3A-Schlafen 12 complex formation, vanadium-containing compounds whose killing depended on the sulfate transporter SLC26A2, the alcohol dependence drug disulfiram, which killed cells with low expression of metallothioneins, and the anti-inflammatory drug tepoxalin, which killed via the multidrug resistance protein ATP-binding cassette subfamily B member 1 (ABCB1). The PRISM drug repurposing resource (https://depmap.org/repurposing) is a starting point to develop new oncology therapeutics, and more rarely, for potential direct clinical translation.},
	language = {en},
	number = {2},
	urldate = {2020-10-28},
	journal = {Nature Cancer},
	author = {Corsello, Steven M. and Nagari, Rohith T. and Spangler, Ryan D. and Rossen, Jordan and Kocak, Mustafa and Bryan, Jordan G. and Humeidi, Ranad and Peck, David and Wu, Xiaoyun and Tang, Andrew A. and Wang, Vickie M. and Bender, Samantha A. and Lemire, Evan and Narayan, Rajiv and Montgomery, Philip and Ben-David, Uri and Garvie, Colin W. and Chen, Yejia and Rees, Matthew G. and Lyons, Nicholas J. and McFarland, James M. and Wong, Bang T. and Wang, Li and Dumont, Nancy and O’Hearn, Patrick J. and Stefan, Eric and Doench, John G. and Harrington, Caitlin N. and Greulich, Heidi and Meyerson, Matthew and Vazquez, Francisca and Subramanian, Aravind and Roth, Jennifer A. and Bittker, Joshua A. and Boehm, Jesse S. and Mader, Christopher C. and Tsherniak, Aviad and Golub, Todd R.},
	month = feb,
	year = {2020},
	note = {Number: 2
Publisher: Nature Publishing Group},
	pages = {235--248},
}

@misc{noauthor_connectopedia_nodate,
	title = {{CONNECTOPEDIA} [clue.io]},
	url = {https://clue.io/connectopedia/pcls},
	urldate = {2020-10-28},
}

@article{subramanian_next_2017,
	title = {A {Next} {Generation} {Connectivity} {Map}: {L1000} platform and the first 1,000,000 profiles},
	volume = {171},
	issn = {0092-8674},
	shorttitle = {A {Next} {Generation} {Connectivity} {Map}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5990023/},
	doi = {10.1016/j.cell.2017.10.049},
	abstract = {We previously piloted the concept of a Connectivity Map (CMap), whereby genes, drugs and disease states are connected by virtue of common gene-expression signatures. Here, we report more than a 1,000-fold scale-up of the CMap as part of the NIH LINCS Consortium, made possible by a new, low-cost, high throughput reduced representation expression profiling method that we term L1000. We show that L1000 is highly reproducible, comparable to RNA sequencing, and suitable for computational inference of the expression levels of 81\% of non-measured transcripts. We further show that the expanded CMap can be used to discover mechanism of action of small molecules, functionally annotate genetic variants of disease genes, and inform clinical trials. The 1.3 million L1000 profiles described here, as well as tools for their analysis, are available at https://clue.io., 
, The next generation Connectivity Map, a large-scale compendium of functional perturbations in cultured human cells coupled to a gene expression read-out, facilitates the discovery of connections between genes, drugs, and diseases.},
	number = {6},
	urldate = {2020-10-28},
	journal = {Cell},
	author = {Subramanian, Aravind and Narayan, Rajiv and Corsello, Steven M. and Peck, David D. and Natoli, Ted E. and Lu, Xiaodong and Gould, Joshua and Davis, John F. and Tubelli, Andrew A. and Asiedu, Jacob K. and Lahr, David L. and Hirschman, Jodi E. and Liu, Zihan and Donahue, Melanie and Julian, Bina and Khan, Mariya and Wadden, David and Smith, Ian and Lam, Daniel and Liberzon, Arthur and Toder, Courtney and Bagul, Mukta and Orzechowski, Marek and Enache, Oana M. and Piccioni, Federica and Johnson, Sarah A. and Lyons, Nicholas J. and Berger, Alice H. and Shamji, Alykhan and Brooks, Angela N. and Vrcic, Anita and Flynn, Corey and Rosains, Jacqueline and Takeda, David and Hu, Roger and Davison, Desiree and Lamb, Justin and Ardlie, Kristin and Hogstrom, Larson and Greenside, Peyton and Gray, Nathanael S. and Clemons, Paul A. and Silver, Serena and Wu, Xiaoyun and Zhao, Wen-Ning and Read-Button, Willis and Wu, Xiaohua and Haggarty, Stephen J. and Ronco, Lucienne V. and Boehm, Jesse S. and Schreiber, Stuart L. and Doench, John G. and Bittker, Joshua A. and Root, David E. and Wong, Bang and Golub, Todd R.},
	month = nov,
	year = {2017},
	pmid = {29195078},
	pmcid = {PMC5990023},
	keywords = {section:background, topic: L1000 and Connectivity Map},
	pages = {1437--1452.e17},
}

@article{dong_variational_2020,
	title = {Variational {Autoencoder} for {Anti}-{Cancer} {Drug} {Response} {Prediction}},
	url = {http://arxiv.org/abs/2008.09763},
	abstract = {Cancer has long been a main cause of human death, and the discovery of new drugs and the customization of cancer therapy have puzzled people for a long time. In order to facilitate the discovery of new anti-cancer drugs and the customization of treatment strategy, we seek to predict the response of different anti-cancer drugs with variational autoencoders (VAE) and multi-layer perceptron (MLP).Our model takes as input gene expression data of cancer cell lines and anti-cancer drug molecular data, and encode these data with \{{\textbackslash}sc \{GeneVae\}\} model, which is an ordinary VAE, and rectified junction tree variational autoencoder (\{{\textbackslash}sc JtVae\}) ({\textbackslash}cite\{jin2018junction\}) model, respectively. Encoded features are processes by a Multi-layer Perceptron (MLP) model to produce a final prediction. We reach an average coefficient of determination (\$R{\textasciicircum}\{2\} = 0.83\$) in predicting drug response on breast cancer cell lines and an average \$R{\textasciicircum}\{2\} {\textgreater} 0.84\$ on pan-cancer cell lines. Additionally, we show that our model can generate unseen effective drug compounds for specific cancer cell lines.},
	urldate = {2020-10-28},
	journal = {arXiv:2008.09763 [cs, stat]},
	author = {Dong, Hongyuan and Xie, Jiaqing and Jing, Zhi and Ren, Dexin},
	month = sep,
	year = {2020},
	note = {arXiv: 2008.09763},
	keywords = {section:background, topic: autoencoder/pca/dr},
}

@article{hutter_prediction_2004,
	title = {Prediction of {Mechanisms} of {Action} of {Antibacterial} {Compounds} by {Gene} {Expression} {Profiling}},
	volume = {48},
	copyright = {Copyright © 2004 American Society for Microbiology},
	issn = {0066-4804, 1098-6596},
	url = {https://aac.asm.org/content/48/8/2838},
	doi = {10.1128/AAC.48.8.2838-2844.2004},
	abstract = {We have generated a database of expression profiles carrying the transcriptional responses of the model organism Bacillus subtilis following treatment with 37 well-characterized antibacterial compounds of different classes. The database was used to build a predictor for the assignment of the mechanisms of action (MoAs) of antibacterial compounds by the use of support vector machines. This predictor was able to correctly classify the MoA class for most compounds tested. Furthermore, we provide evidence that the in vivo MoA of hexachlorophene does not match the MoA predicted from in vitro data, a situation frequently faced in drug discovery. A database of this kind may facilitate the prioritization of novel antibacterial entities in drug discovery programs. Potential applications and limitations are discussed.},
	language = {en},
	number = {8},
	urldate = {2020-10-28},
	journal = {Antimicrobial Agents and Chemotherapy},
	author = {Hutter, Bernd and Schaab, Christoph and Albrecht, Sebastian and Borgmann, Matthias and Brunner, Nina A. and Freiberg, Christoph and Ziegelbauer, Karl and Rock, Charles O. and Ivanov, Igor and Loferer, Hannes},
	month = aug,
	year = {2004},
	pmid = {15273089},
	note = {Publisher: American Society for Microbiology Journals
Section: MECHANISMS OF ACTION: PHYSIOLOGICAL EFFECTS},
	pages = {2838--2844},
}

@article{mattiazzi_inference_2010,
	title = {Inference of the {Molecular} {Mechanism} of {Action} from {Genetic} {Interaction} and {Gene} {Expression} {Data}},
	volume = {14},
	issn = {1536-2310, 1557-8100},
	url = {http://www.liebertpub.com/doi/10.1089/omi.2009.0144},
	doi = {10.1089/omi.2009.0144},
	language = {en},
	number = {4},
	urldate = {2020-10-27},
	journal = {OMICS: A Journal of Integrative Biology},
	author = {Mattiazzi, Mojca and Curk, Tomaž and Križaj, Igor and Zupan, Blaž and Petrovič, Uroš},
	month = aug,
	year = {2010},
	keywords = {section:background, topic: moa},
	pages = {357--367},
}

@article{woo_elucidating_2015,
	title = {Elucidating {Compound} {Mechanism} of {Action} by {Network} {Perturbation} {Analysis}},
	volume = {162},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867415006996},
	doi = {10.1016/j.cell.2015.05.056},
	abstract = {Genome-wide identiﬁcation of the mechanism of action (MoA) of small-molecule compounds characterizing their targets, effectors, and activity modulators represents a highly relevant yet elusive goal, with critical implications for assessment of compound efﬁcacy and toxicity. Current approaches are labor intensive and mostly limited to elucidating high-afﬁnity binding target proteins. We introduce a regulatory network-based approach that elucidates genomewide MoA proteins based on the assessment of the global dysregulation of their molecular interactions following compound perturbation. Analysis of cellular perturbation proﬁles identiﬁed established MoA proteins for 70\% of the tested compounds and elucidated novel proteins that were experimentally validated. Finally, unknown-MoA compound analysis revealed altretamine, an anticancer drug, as an inhibitor of glutathione peroxidase 4 lipid repair activity, which was experimentally conﬁrmed, thus revealing unexpected similarity to the activity of sulfasalazine. This suggests that regulatory network analysis can provide valuable mechanistic insight into the elucidation of small-molecule MoA and compound similarity.},
	language = {en},
	number = {2},
	urldate = {2020-10-27},
	journal = {Cell},
	author = {Woo, Jung Hoon and Shimoni, Yishai and Yang, Wan Seok and Subramaniam, Prem and Iyer, Archana and Nicoletti, Paola and Rodríguez Martínez, María and López, Gonzalo and Mattioli, Michela and Realubit, Ronald and Karan, Charles and Stockwell, Brent R. and Bansal, Mukesh and Califano, Andrea},
	month = jul,
	year = {2015},
	keywords = {section:background, topic: moa},
	pages = {441--451},
}

@article{way_extracting_2018,
	title = {Extracting a biologically relevant latent space from cancer transcriptomes with variational autoencoders},
	volume = {23},
	issn = {2335-6936},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5728678/},
	abstract = {The Cancer Genome Atlas (TCGA) has profiled over 10,000 tumors across 33 different cancer-types for many genomic features, including gene expression levels. Gene expression measurements capture substantial information about the state of each tumor. Certain classes of deep neural network models are capable of learning a meaningful latent space. Such a latent space could be used to explore and generate hypothetical gene expression profiles under various types of molecular and genetic perturbation. For example, one might wish to use such a model to predict a tumor’s response to specific therapies or to characterize complex gene expression activations existing in differential proportions in different tumors. Variational autoencoders (VAEs) are a deep neural network approach capable of generating meaningful latent spaces for image and text data. In this work, we sought to determine the extent to which a VAE can be trained to model cancer gene expression, and whether or not such a VAE would capture biologically-relevant features. In the following report, we introduce a VAE trained on TCGA pan-cancer RNA-seq data, identify specific patterns in the VAE encoded features, and discuss potential merits of the approach. We name our method “Tybalt” after an instigative, cat-like character who sets a cascading chain of events in motion in Shakespeare’s “Romeo and Juliet”. From a systems biology perspective, Tybalt could one day aid in cancer stratification or predict specific activated expression patterns that would result from genetic changes or treatment effects.},
	urldate = {2020-10-27},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Way, Gregory P. and Greene, Casey S.},
	year = {2018},
	pmid = {29218871},
	pmcid = {PMC5728678},
	keywords = {topic: autoencoder/pca/dr},
	pages = {80--91},
}

@misc{noauthor_180208465_nodate,
	title = {[1802.08465] {AEkNN}: {An} {AutoEncoder} {kNN}-based classifier with built-in dimensionality reduction},
	url = {https://arxiv.org/abs/1802.08465},
	urldate = {2020-10-27},
}

@article{ma_deep_2015,
	title = {Deep {Neural} {Nets} as a {Method} for {Quantitative} {Structure}–{Activity} {Relationships}},
	volume = {55},
	issn = {1549-9596, 1549-960X},
	url = {https://pubs.acs.org/doi/10.1021/ci500747n},
	doi = {10.1021/ci500747n},
	language = {en},
	number = {2},
	urldate = {2020-10-27},
	journal = {Journal of Chemical Information and Modeling},
	author = {Ma, Junshui and Sheridan, Robert P. and Liaw, Andy and Dahl, George E. and Svetnik, Vladimir},
	month = feb,
	year = {2015},
	pages = {263--274},
}

@article{freedman_hunting_2019,
	title = {Hunting for {New} {Drugs} with {AI}},
	volume = {576},
	copyright = {2020 Nature},
	url = {https://www.nature.com/articles/d41586-019-03846-0},
	doi = {10.1038/d41586-019-03846-0},
	abstract = {The pharmaceutical industry is in a drug-discovery slump. How much can AI help?},
	language = {en},
	number = {7787},
	urldate = {2020-10-27},
	journal = {Nature},
	author = {Freedman, David H.},
	month = dec,
	year = {2019},
	note = {Number: 7787
Publisher: Nature Publishing Group},
	pages = {S49--S53},
}

@article{adeyelu_computational_nodate,
	title = {Computational {Approaches} for {Predicting} {Drug} {Targets}},
	language = {en},
	author = {Adeyelu, Tolulope Tosin},
	keywords = {section: motivation, section:background, topic: drug discovery, type: example dissertation},
	pages = {209},
}

@phdthesis{noauthor_deep_nodate,
	title = {Deep {Learning} for {Drug} {Discovery} {Dissertation}},
	keywords = {topic: deep learning, topic: drug discovery, type: example dissertation},
}

@article{bica_unsupervised_2020,
	title = {Unsupervised generative and graph representation learning for modelling cell differentiation},
	volume = {10},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-020-66166-8},
	doi = {10.1038/s41598-020-66166-8},
	language = {en},
	number = {1},
	urldate = {2020-10-26},
	journal = {Scientific Reports},
	author = {Bica, Ioana and Andrés-Terré, Helena and Cvejic, Ana and Liò, Pietro},
	month = dec,
	year = {2020},
	keywords = {topic: autoencoder/pca/dr},
	pages = {9790},
}

@article{adam_machine_2020,
	title = {Machine learning approaches to drug response prediction: challenges and recent progress},
	volume = {4},
	issn = {2397-768X},
	shorttitle = {Machine learning approaches to drug response prediction},
	url = {http://www.nature.com/articles/s41698-020-0122-1},
	doi = {10.1038/s41698-020-0122-1},
	language = {en},
	number = {1},
	urldate = {2020-10-25},
	journal = {npj Precision Oncology},
	author = {Adam, George and Rampášek, Ladislav and Safikhani, Zhaleh and Smirnov, Petr and Haibe-Kains, Benjamin and Goldenberg, Anna},
	month = dec,
	year = {2020},
	keywords = {section: motivation, section:background},
	pages = {19},
}

@article{eraslan_deep_2019,
	title = {Deep learning: new computational modelling techniques for genomics},
	volume = {20},
	issn = {1471-0056, 1471-0064},
	shorttitle = {Deep learning},
	url = {http://www.nature.com/articles/s41576-019-0122-6},
	doi = {10.1038/s41576-019-0122-6},
	language = {en},
	number = {7},
	urldate = {2020-10-26},
	journal = {Nature Reviews Genetics},
	author = {Eraslan, Gökcen and Avsec, Žiga and Gagneur, Julien and Theis, Fabian J.},
	month = jul,
	year = {2019},
	keywords = {section:background, topic: deep learning},
	pages = {389--403},
}

@article{chen_rise_2018,
	title = {The rise of deep learning in drug discovery},
	volume = {23},
	issn = {13596446},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1359644617303598},
	doi = {10.1016/j.drudis.2018.01.039},
	language = {en},
	number = {6},
	urldate = {2020-10-25},
	journal = {Drug Discovery Today},
	author = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
	month = jun,
	year = {2018},
	keywords = {section:background},
	pages = {1241--1250},
}

@misc{noauthor_reinforcement_2018,
	title = {Reinforcement learning’s foundational flaw},
	url = {https://thegradient.pub/why-rl-is-flawed/},
	abstract = {By definition, learning from scratch is just about the least sample-efficient approach there can be.},
	language = {en},
	urldate = {2020-08-07},
	journal = {The Gradient},
	month = jul,
	year = {2018},
	note = {Library Catalog: thegradient.pub},
}

@article{nijssen_writing_nodate,
	title = {Writing a {Bachelor} {Thesis} in {Computer} {Science}},
	language = {en},
	author = {Nijssen, Siegfried},
	pages = {37},
}

@article{chollet_measure_2019,
	title = {On the {Measure} of {Intelligence}},
	url = {http://arxiv.org/abs/1911.01547},
	abstract = {To make deliberate progress towards more intelligent and more human-like artificial systems, we need to be following an appropriate feedback signal: we need to be able to define and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abundance of attempts to define and measure intelligence, across both the fields of psychology and AI. We summarize and critically assess these definitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates towards benchmarking intelligence by comparing the skill exhibited by AIs and humans at specific tasks such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow experimenters to "buy" arbitrary levels of skills for a system, in a way that masks the system's own generalization power. We then articulate a new formal definition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efficiency and highlighting the concepts of scope, generalization difficulty, priors, and experience. Using this definition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.},
	urldate = {2020-07-18},
	journal = {arXiv:1911.01547 [cs]},
	author = {Chollet, François},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.01547},
}

@article{turner_evolving_nodate,
	title = {Evolving {Artiﬁcial} {Neural} {Networks} using {Cartesian} {Genetic} {Programming}},
	language = {en},
	author = {Turner, Andrew James},
	pages = {336},
}

@misc{noauthor_evolution_2017,
	title = {Evolution {Strategies} as a {Scalable} {Alternative} to {Reinforcement} {Learning}},
	url = {https://openai.com/blog/evolution-strategies/},
	abstract = {We've discovered that evolution strategies (ES), an optimization technique that's been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks, while overcoming many of RL's inconveniences.},
	language = {en},
	urldate = {2020-07-16},
	journal = {OpenAI},
	month = mar,
	year = {2017},
	note = {Library Catalog: openai.com},
}

@article{fernando_convolution_2016,
	title = {Convolution by {Evolution}: {Differentiable} {Pattern} {Producing} {Networks}},
	shorttitle = {Convolution by {Evolution}},
	url = {http://arxiv.org/abs/1606.02580},
	abstract = {In this work we introduce a differentiable version of the Compositional Pattern Producing Network, called the DPPN. Unlike a standard CPPN, the topology of a DPPN is evolved but the weights are learned. A Lamarckian algorithm, that combines evolution and learning, produces DPPNs to reconstruct an image. Our main result is that DPPNs can be evolved/trained to compress the weights of a denoising autoencoder from 157684 to roughly 200 parameters, while achieving a reconstruction accuracy comparable to a fully connected network with more than two orders of magnitude more parameters. The regularization ability of the DPPN allows it to rediscover (approximate) convolutional network architectures embedded within a fully connected architecture. Such convolutional architectures are the current state of the art for many computer vision applications, so it is satisfying that DPPNs are capable of discovering this structure rather than having to build it in by design. DPPNs exhibit better generalization when tested on the Omniglot dataset after being trained on MNIST, than directly encoded fully connected autoencoders. DPPNs are therefore a new framework for integrating learning and evolution.},
	urldate = {2020-07-01},
	journal = {arXiv:1606.02580 [cs]},
	author = {Fernando, Chrisantha and Banarse, Dylan and Reynolds, Malcolm and Besse, Frederic and Pfau, David and Jaderberg, Max and Lanctot, Marc and Wierstra, Daan},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.02580},
}
